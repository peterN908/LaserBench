# LaserBench üî¥

A benchmark for testing LLM spatial reasoning through laser mirror puzzles.

**[GitHub Repository](https://github.com/peterN908/LaserBench)**

## What is LaserBench?

LaserBench tests whether AI models can correctly trace a laser beam through a grid containing mirrors. This requires:

- **Spatial reasoning**: Understanding 2D grid coordinates
- **Rule following**: Applying mirror reflection rules consistently
- **Sequential tracking**: Maintaining state across multiple bounces

## The Puzzle

```
    A B C D E F G H
  +-----------------+
 1| . . . . . . . . |
 2| . \ . / . . . . |
 3|>. . . . \ . . . |
 4| . . . . . . / . |
 5| . . . . . . . . |
  +-----------------+
```

- Laser enters from the left at the `>` arrow
- `/` and `\` mirrors bounce the laser 90¬∞
- Goal: Determine which edge and position the laser exits

### Mirror Rules

| Direction | `/` Mirror | `\` Mirror |
|-----------|------------|------------|
| ‚Üí Right   | ‚Üë Up       | ‚Üì Down     |
| ‚Üê Left    | ‚Üì Down     | ‚Üë Up       |
| ‚Üë Up      | ‚Üí Right    | ‚Üê Left     |
| ‚Üì Down    | ‚Üê Left     | ‚Üí Right    |

## Puzzle Sizes

| Size   | Grid          | Mirrors | Min Bounces |
|--------|---------------|---------|-------------|
| Small  | 5-6 √ó 6-8     | 4-6     | 3           |
| Medium | 7-9 √ó 9-12    | 7-10    | 5           |
| Large  | 10-12 √ó 13-16 | 18-24   | 8           |

Puzzles are generated by sampling 100 random configurations and keeping the one with the **highest bounce count**, ensuring maximum complexity.

## Running Benchmarks

### Prerequisites

```bash
pip install google-genai python-dotenv openai anthropic matplotlib
```

### Environment Variables

Create a `.env` file:

```env
GEMINI_API_KEY=your-key
OPENAI_API_KEY=your-key
ANTHROPIC_API_KEY=your-key
GROK_API_KEY=your-key
```

### Run Tests

```bash
# Test Gemini models
python scripts/test_gemini.py

# Test all providers (OpenAI, Anthropic, Grok)
python scripts/test_all_providers.py
```

## Web Interface

```bash
npm install
npm run dev
```

Visit `http://localhost:3000` to:
- Generate random puzzles
- Fire the laser and watch it trace
- Copy puzzles as ASCII for testing
- View benchmark results

## Results

Results are saved to `scripts/results/` as JSON files with accuracy metrics per model.

### Supported Models

**Anthropic:**
- Claude Sonnet 4.5
- Claude Opus 4.5

**Google:**
- Gemini 3 Pro (with thinking)
- Gemini Flash
- Gemini 2.5 Pro
- Gemini Flash Lite

**OpenAI:**
- GPT-5.1 / o-series models

### Sample Results (Large Puzzles, n=20)

| Model | Accuracy |
|-------|----------|
| Gemini 3 Pro Preview | 100% |
| Gemini Flash | 90% |
| Gemini 2.5 Pro | 85% |
| Gemini Flash Lite | 70% |

## License

MIT

---

Built for evaluating LLM spatial reasoning capabilities.
